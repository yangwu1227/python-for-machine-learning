{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac902345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import tracemalloc\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "from wsri import somers_d_roc_auc, somers_d_two_pointers, wsri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1997d2",
   "metadata": {},
   "source": [
    "## Benchmark vs. Monitoring Setup\n",
    "\n",
    "* **Benchmark**: A fixed reference period (e.g., 2023 data) that we treat as the \"gold standard\" or baseline distribution of scores and outcomes.\n",
    "* **Monitoring**: A newer period (e.g., Q1 2024 data) that we want to evaluate for stability relative to the benchmark.\n",
    "\n",
    "The purpose of **wSRI** here is to ask: *if the score-label relationship in monitoring looks different from benchmark, how much of that difference reflects population shift rather than true deterioration in model rank-ordering?*\n",
    "\n",
    "---\n",
    "\n",
    "### Why Weight the Benchmark\n",
    "\n",
    "Weighting only the **benchmark** population makes sense because:\n",
    "\n",
    "* **Benchmark as reference**: We want monitoring data to be evaluated *as is*, because it reflects the actual, current population distribution.\n",
    "* **Benchmark rescaled**: By reweighting benchmark bins to match the marginal distribution of scores in monitoring, we are forcing the benchmark to look like e.g. \"what 2023 would have looked like under the 2024 score distribution.\"\n",
    "* **Apples-to-apples comparability**: Without reweighting, Somers’ D differences could be confounded by the fact that the monitoring period simply has more/less accounts in certain score ranges (not necessarily because the rank-order power of the model changed).\n",
    "\n",
    "So the weighting isolates the effect of **conditional rank performance** (score <-> label relationship) rather than **population score mix**.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Not Weight Monitoring\n",
    "\n",
    "If we weighted **monitoring** to benchmark:\n",
    "\n",
    "* We’d be discarding real, current information about the new population distribution.\n",
    "* The monitoring Somers’ D would be artificially “distorted back” to the 2023 distribution, making it less diagnostic for drift.\n",
    "* We’d risk underestimating deterioration if population shift itself is part of what we want to detect.\n",
    "\n",
    "---\n",
    "\n",
    "### Covariate Shift\n",
    "\n",
    "Formally, weighting only benchmark approximates a **covariate-shift correction** problem:\n",
    "\n",
    "* Assume conditional outcome distributions *P(y|score)* are stable in both periods (or at least what we want to test).\n",
    "* But the marginal score distribution *P(score)* has shifted.\n",
    "* Reweighting benchmark to monitoring ensures we compare *P(y|score)* fairly across periods.\n",
    "\n",
    "This is consistent with the idea of “importance weighting” in domain adaptation:\n",
    "\n",
    "$$\n",
    "w(x) = \\frac{P_{\\text{monitoring}}(x)}{P_{\\text{benchmark}}(x)}\n",
    "$$\n",
    "\n",
    "where here *x* = score bins.\n",
    "\n",
    "It makes sense to weight the **benchmark** and not the monitoring because we want to transform the reference into the monitoring population’s shape, ensuring comparability. Monitoring stays unweighted so it reflects reality. This lets the ratio (monitoring Somers’ D / reweighted benchmark Somers’ D) isolate *rank-order stability*, not population differences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e4329",
   "metadata": {},
   "source": [
    "## Weighted Somers’ $D$ via Two-Pointer Sweep\n",
    "\n",
    "### Variables\n",
    "\n",
    "#### Inputs\n",
    "\n",
    "* `scores`: 1D array of predicted scores; shape $(n,)$. Element $s_i \\in \\mathbb{R}$.\n",
    "* `labels`: 1D array of binary ground-truth labels; shape $(n,)$. Element $y_i \\in \\{0,1\\}$.\n",
    "* `weights`: 1D array of non-negative sample weights; shape $(n,)$. Element $w_i \\ge 0$.\n",
    "\n",
    "#### Derived arrays (post-sort, contiguous for Numba)\n",
    "\n",
    "* `sorted_indices`: permutation that sorts `scores` in non-decreasing order.\n",
    "* `scores_array`: `scores[sorted_indices]`; ascending.\n",
    "* `labels_array`: `labels[sorted_indices]`; aligned to `scores_array`.\n",
    "* `weights_array`: `weights[sorted_indices]`; aligned to `scores_array`.\n",
    "\n",
    "#### Scalar counts / masses\n",
    "\n",
    "* `n_total`: integer $= n$, total number of observations.\n",
    "* `n_pos`: float $= \\sum_{i: y_i=1} w_i$, total **positive weight** (“mass”).\n",
    "* `n_neg`: float $= \\sum_{i: y_i=0} w_i$, total **negative weight** (“mass”).\n",
    "\n",
    "#### Notations\n",
    "\n",
    "* $P := \\{j : y_j = 1\\}$ (positive indices), $N := \\{i : y_i = 0\\}$ (negative indices).\n",
    "* For an anchor threshold $t$:\n",
    "\n",
    "  * $D(t) := \\{j \\in P : s_j < t\\}$ (positives **below** $t$, discordant w\\.r.t. a negative at $t$).\n",
    "  * $C(t) := \\{j \\in P : s_j > t\\}$ (positives **above** $t$, concordant w\\.r.t. a negative at $t$).\n",
    "* $\\mathbb{1}[\\cdot]$: indicator function (1 if condition holds, else 0).\n",
    "\n",
    "\n",
    "#### Sweep-state (maintained during the pass)\n",
    "\n",
    "* `discordant_contrib`: float; current $\\sum_{j \\in P: s_j < t} w_j$, the total positive mass **strictly below** the current anchor threshold $t$.\n",
    "* `concordant_contrib`: float; current $\\sum_{j \\in P: s_j > t} w_j$, the total positive mass **strictly above** $t$.\n",
    "* `numerator`: float; accumulates $\\sum_{i \\in N} w_i \\left(\\text{concordant\\_contrib} - \\text{discordant\\_contrib}\\right)$.\n",
    "\n",
    "#### Pointers / indices\n",
    "\n",
    "* `discordant_index`: integer pointer $r$; smallest index with $s_r \\ge t$. All positive indices $< r$ have $s_j < t$ and are counted in `discordant_contrib`.\n",
    "* `concordant_index`: integer pointer $q$; smallest index with $s_q > t$. All positive indices $\\le q-1$ have $s_j \\le t$ and have been **removed** from the concordant pool.\n",
    "* `current_false_score`: float $t$ = score of the current **negative** anchor; i.e., the threshold relative to which positives are partitioned.\n",
    "\n",
    "---\n",
    "\n",
    "### Objective\n",
    "\n",
    "Weighted Somers’ $D$ for binary outcomes is\n",
    "\n",
    "$$\n",
    "D \\;=\\;\n",
    "\\frac{\\displaystyle \\sum_{i \\in N} \\sum_{j \\in P} w_i w_j \\Big(\\mathbb{1}[s_j > s_i] - \\mathbb{1}[s_j < s_i]\\Big)}\n",
    "{\\displaystyle \\sum_{i \\in N} \\sum_{j \\in P} w_i w_j}\n",
    "\\;\\in [-1,1]\n",
    "$$\n",
    "\n",
    "Equivalently, if we anchor on a negative with threshold $t = s_i$, its contribution is\n",
    "\n",
    "$$\n",
    "w_i\\left(\n",
    "\\sum_{j \\in P: s_j > t} w_j\n",
    "\\;-\\;\n",
    "\\sum_{j \\in P: s_j < t} w_j\n",
    "\\right)\n",
    "\\;=\\; w_i\\big(\\text{concordant mass} - \\text{discordant mass}\\big)\n",
    "$$\n",
    "\n",
    "Ties receive zero contribution because neither $s_j > t$ nor $s_j < t$ is true when $s_j = t$.\n",
    "\n",
    "---\n",
    "\n",
    "### Algorithm (two-pointer sweep)\n",
    "\n",
    "1. **Sort once.** Compute `sorted_indices = argsort(scores)` and build contiguous `scores_array`, `labels_array`, `weights_array`.\n",
    "\n",
    "2. **Accumulate class masses.**\n",
    "\n",
    "   * $n_{\\text{pos}} = \\sum_{y_i=1} w_i$, $n_{\\text{neg}} = \\sum_{y_i=0} w_i$.\n",
    "   * If $n_{\\text{pos}}=0$ or $n_{\\text{neg}}=0$, return $0.0$ (no cross-class pairs).\n",
    "\n",
    "3. **Initialize sweep state.**\n",
    "\n",
    "   * `discordant_contrib = 0.0` (no positives yet confirmed below $t$).\n",
    "   * `concordant_contrib = n_pos` (initially, all positives are potentially $> t$).\n",
    "   * `discordant_index = 0`, `concordant_index = 0`, `numerator = 0.0`.\n",
    "\n",
    "4. **Single forward pass.** For each index $i = 0,\\dots,n-1$ in score-sorted order:\n",
    "\n",
    "   * If `labels_array[i] == 0` (a **negative** anchor), set $t = \\text{current\\_false\\_score} = \\text{scores\\_array}[i]$.\n",
    "   * **Advance `discordant_index`** while $\\text{scores\\_array}[r] < t$:\n",
    "\n",
    "     * If $\\text{labels\\_array}[r] == 1$, add $\\text{weights\\_array}[r]$ to `discordant_contrib`.\n",
    "     * Increment $r=$ `discordant_index`.\n",
    "     * Result: `discordant_contrib` $= \\sum_{j \\in P: s_j < t} w_j$.\n",
    "   * **Advance `concordant_index`** while $\\text{scores\\_array}[q] \\le t$:\n",
    "\n",
    "     * If $\\text{labels\\_array}[q] == 1$, subtract $\\text{weights\\_array}[q]$ from `concordant_contrib`.\n",
    "     * Increment $q=$ `concordant_index`.\n",
    "     * Result: `concordant_contrib` $= \\sum_{j \\in P: s_j > t} w_j$.\n",
    "   * **Accumulate anchor contribution:**\n",
    "\n",
    "     $$\n",
    "     \\text{numerator} \\;{+}{=}\\; \\text{weights\\_array}[i]\\,\n",
    "     \\big(\\text{concordant\\_contrib} - \\text{discordant\\_contrib}\\big).\n",
    "     $$\n",
    "\n",
    "5. **Normalize.**\n",
    "\n",
    "$$\n",
    "\\frac{\\text{numerator}}{n_{\\text{neg}} \\cdot n_{\\text{pos}}}\n",
    "\\;=\\;\n",
    "\\frac{\\sum_{i \\in N} w_i \\big(\\sum_{j \\in P: s_j > s_i} w_j - \\sum_{j \\in P: s_j < s_i} w_j\\big)}\n",
    "{\\left(\\sum_{i \\in N} w_i\\right)\\left(\\sum_{j \\in P} w_j\\right)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Why pointers never reset\n",
    "\n",
    "* Scores are processed in **non-decreasing** order. Let $t_k$ and $t_{k+1}$ be successive negative anchors; then $t_{k+1} \\ge t_k$.\n",
    "* As $t$ increases:\n",
    "\n",
    "  * $D(t)$ (positives with $s_j < t$) is **monotone non-decreasing**; once a positive enters $D(t)$, it never leaves. This is exactly what `discordant_index` tracks using “<”.\n",
    "  * $C(t)$ (positives with $s_j > t$) is **monotone non-increasing**; once a positive is no longer $> t$ (i.e., $s_j \\le t$), it never re-enters. This is what `concordant_index` enforces using “$\\le$”.\n",
    "* Hence both pointers move forward at most $n$ steps total; no resets are necessary.\n",
    "\n",
    "---\n",
    "\n",
    "### Tie handling\n",
    "\n",
    "* The discordant pointer uses **strict** “<” and the concordant pointer uses “$\\le$”.\n",
    "* For $s_j = t$:\n",
    "\n",
    "  * Not counted into `discordant_contrib` (not < $t$).\n",
    "  * Removed from `concordant_contrib` (no longer $>\\,t$).\n",
    "* Net effect: ties contribute $0$ to the numerator, matching the Somers’ $D$ definition.\n",
    "\n",
    "---\n",
    "\n",
    "### Correctness invariants (maintained at each negative anchor)\n",
    "\n",
    "For the current threshold $t$:\n",
    "\n",
    "$$\n",
    "\\text{discordant\\_contrib} = \\sum_{j \\in P: s_j < t} w_j,\n",
    "\\qquad\n",
    "\\text{concordant\\_contrib} = \\sum_{j \\in P: s_j > t} w_j,\n",
    "$$\n",
    "\n",
    "and the instantaneous contribution is\n",
    "\n",
    "$$\n",
    "w_i\\big(\\text{concordant\\_contrib} - \\text{discordant\\_contrib}\\big).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Complexity and numerical notes\n",
    "\n",
    "* **Time:** $O(n \\log n)$ for sorting + $O(n)$ for the sweep; each element is touched by each pointer at most once.\n",
    "* **Space:** $O(n)$ for sorted views; in-place reordering avoided to keep inputs unchanged.\n",
    "* **Numerics:** Use 64-bit floats for accumulators (`concordant_contrib`, `discordant_contrib`, `numerator`) to reduce rounding error on large weights. Guard for $n_{\\text{pos}}=0$ or $n_{\\text{neg}}=0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f470a7",
   "metadata": {},
   "source": [
    "## Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be3d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng: np.random.Generator = np.random.default_rng(seed=1227)\n",
    "\n",
    "sample_sizes: np.typing.NDArray[np.int64] = np.array(\n",
    "    [5_000, 50_000, 500_000, 5_000_000, 50_000_000]\n",
    ")\n",
    "\n",
    "score_column: str = \"score\"\n",
    "label_column: str = \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a2a45f",
   "metadata": {},
   "source": [
    "## JIT Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "278107ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSRI: 4.687046070922117\n"
     ]
    }
   ],
   "source": [
    "# Warm-up for JIT since the first call to a numba JIT function includes a one-time compilation overhead\n",
    "warmup_sample_size: int = 1_000\n",
    "benchmark: pl.DataFrame = pl.DataFrame(\n",
    "    {\n",
    "        score_column: rng.uniform(0, 1, warmup_sample_size).astype(np.float64),\n",
    "        label_column: rng.choice([0, 1], warmup_sample_size).astype(np.int8),\n",
    "    }\n",
    ").lazy()\n",
    "\n",
    "monitoring: pl.DataFrame = pl.DataFrame(\n",
    "    {\n",
    "        score_column: rng.uniform(0, 1, warmup_sample_size).astype(np.float64),\n",
    "        label_column: rng.choice([0, 1], warmup_sample_size).astype(np.int8),\n",
    "    }\n",
    ").lazy()\n",
    "\n",
    "wsri_value: float = wsri(\n",
    "    benchmark=benchmark,\n",
    "    monitoring=monitoring,\n",
    "    score_column=score_column,\n",
    "    label_column=label_column,\n",
    "    quantiles=20,\n",
    "    callback=somers_d_two_pointers,\n",
    ")\n",
    "\n",
    "print(f\"WSRI: {wsri_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af584e1c",
   "metadata": {},
   "source": [
    "## Wall Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9791127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 5000\n",
      "Sample size: 50000\n",
      "Sample size: 500000\n",
      "Sample size: 5000000\n",
      "Sample size: 50000000\n"
     ]
    }
   ],
   "source": [
    "wall_time_results: List[Dict[str, float]] = []\n",
    "data_sets: List[Dict[str, pl.LazyFrame]] = []\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    print(f\"Sample size: {sample_size}\")\n",
    "\n",
    "    benchmark: pl.LazyFrame = pl.DataFrame(\n",
    "        {\n",
    "            score_column: rng.uniform(0, 1, sample_size).astype(np.float64),\n",
    "            label_column: rng.choice([0, 1], sample_size).astype(np.int8),\n",
    "        }\n",
    "    ).lazy()\n",
    "\n",
    "    monitoring: pl.LazyFrame = pl.DataFrame(\n",
    "        {\n",
    "            score_column: rng.uniform(0, 1, sample_size).astype(np.float64),\n",
    "            label_column: rng.choice([0, 1], sample_size).astype(np.int8),\n",
    "        }\n",
    "    ).lazy()\n",
    "\n",
    "    data_sets.append({\"benchmark\": benchmark, \"monitoring\": monitoring})\n",
    "\n",
    "    start_time_two_pointers: float = time.perf_counter()\n",
    "    wsri_two_pointers: float = wsri(\n",
    "        benchmark=benchmark,\n",
    "        monitoring=monitoring,\n",
    "        score_column=score_column,\n",
    "        label_column=label_column,\n",
    "        quantiles=20,\n",
    "        callback=somers_d_two_pointers,\n",
    "    )\n",
    "    time_two_pointers: float = time.perf_counter() - start_time_two_pointers\n",
    "\n",
    "    start_time_roc_auc: float = time.perf_counter()\n",
    "    wsri_roc_auc: float = wsri(\n",
    "        benchmark=benchmark,\n",
    "        monitoring=monitoring,\n",
    "        score_column=score_column,\n",
    "        label_column=label_column,\n",
    "        quantiles=20,\n",
    "        callback=somers_d_roc_auc,\n",
    "    )\n",
    "    time_roc_auc: float = time.perf_counter() - start_time_roc_auc\n",
    "\n",
    "    wall_time_results.append(\n",
    "        {\n",
    "            \"sample_size\": sample_size,\n",
    "            \"wsri_two_pointers\": wsri_two_pointers,\n",
    "            \"wsri_roc_auc\": wsri_roc_auc,\n",
    "            \"time_two_pointers\": time_two_pointers,\n",
    "            \"time_roc_auc\": time_roc_auc,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25af32e3",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794ce449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 5000\n",
      "Sample size: 50000\n",
      "Sample size: 500000\n",
      "Sample size: 5000000\n",
      "Sample size: 50000000\n"
     ]
    }
   ],
   "source": [
    "memory_results: List[Dict[str, float]] = []\n",
    "\n",
    "for sample_size, data_set in zip(sample_sizes, data_sets):\n",
    "    print(f\"Sample size: {sample_size}\")\n",
    "\n",
    "    benchmark: pl.LazyFrame = data_set[\"benchmark\"]\n",
    "    monitoring: pl.LazyFrame = data_set[\"monitoring\"]\n",
    "\n",
    "    tracemalloc.start()\n",
    "    _ = wsri(\n",
    "        benchmark=benchmark,\n",
    "        monitoring=monitoring,\n",
    "        score_column=score_column,\n",
    "        label_column=label_column,\n",
    "        quantiles=20,\n",
    "        callback=somers_d_two_pointers,\n",
    "    )\n",
    "    _, peak_mem_two_pointers = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    tracemalloc.start()\n",
    "    _ = wsri(\n",
    "        benchmark=benchmark,\n",
    "        monitoring=monitoring,\n",
    "        score_column=score_column,\n",
    "        label_column=label_column,\n",
    "        quantiles=20,\n",
    "        callback=somers_d_roc_auc,\n",
    "    )\n",
    "    _, peak_mem_roc_auc = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    memory_results.append(\n",
    "        {\n",
    "            \"sample_size\": sample_size,\n",
    "            \"peak_mem_two_pointers_mb\": peak_mem_two_pointers / 10**6,\n",
    "            \"peak_mem_roc_auc_mb\": peak_mem_roc_auc / 10**6,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d1dc1",
   "metadata": {},
   "source": [
    "## Combine Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad522f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sample_size</th><th>wsri_two_pointers</th><th>wsri_roc_auc</th><th>time_two_pointers</th><th>time_roc_auc</th><th>peak_mem_two_pointers_mb</th><th>peak_mem_roc_auc_mb</th><th>speedup_two_pointers_vs_roc_auc</th><th>memory_two_pointers_vs_roc_auc</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>5000</td><td>-0.3375</td><td>-0.3375</td><td>0.0068</td><td>0.0083</td><td>0.1305</td><td>0.502</td><td>1.2172</td><td>3.8457</td></tr><tr><td>50000</td><td>1.5518</td><td>1.5518</td><td>0.0219</td><td>0.0259</td><td>1.2534</td><td>4.5766</td><td>1.1857</td><td>3.6515</td></tr><tr><td>500000</td><td>-0.3074</td><td>-0.3074</td><td>0.2069</td><td>0.2441</td><td>12.5036</td><td>45.0766</td><td>1.18</td><td>3.6051</td></tr><tr><td>5000000</td><td>0.868</td><td>0.868</td><td>2.1829</td><td>2.7142</td><td>125.0035</td><td>450.0768</td><td>1.2434</td><td>3.6005</td></tr><tr><td>50000000</td><td>-0.529</td><td>-0.529</td><td>26.1408</td><td>31.7893</td><td>1250.0041</td><td>4500.0769</td><td>1.2161</td><td>3.6</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ sample_si ┆ wsri_two_ ┆ wsri_roc_ ┆ time_two_ ┆ … ┆ peak_mem_ ┆ peak_mem_ ┆ speedup_t ┆ memory_t │\n",
       "│ ze        ┆ pointers  ┆ auc       ┆ pointers  ┆   ┆ two_point ┆ roc_auc_m ┆ wo_pointe ┆ wo_point │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ers_mb    ┆ b         ┆ rs_vs_roc ┆ ers_vs_r │\n",
       "│ i64       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ ---       ┆ _au…      ┆ oc_auc   │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 5000      ┆ -0.3375   ┆ -0.3375   ┆ 0.0068    ┆ … ┆ 0.1305    ┆ 0.502     ┆ 1.2172    ┆ 3.8457   │\n",
       "│ 50000     ┆ 1.5518    ┆ 1.5518    ┆ 0.0219    ┆ … ┆ 1.2534    ┆ 4.5766    ┆ 1.1857    ┆ 3.6515   │\n",
       "│ 500000    ┆ -0.3074   ┆ -0.3074   ┆ 0.2069    ┆ … ┆ 12.5036   ┆ 45.0766   ┆ 1.18      ┆ 3.6051   │\n",
       "│ 5000000   ┆ 0.868     ┆ 0.868     ┆ 2.1829    ┆ … ┆ 125.0035  ┆ 450.0768  ┆ 1.2434    ┆ 3.6005   │\n",
       "│ 50000000  ┆ -0.529    ┆ -0.529    ┆ 26.1408   ┆ … ┆ 1250.0041 ┆ 4500.0769 ┆ 1.2161    ┆ 3.6      │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wall_time_data: pl.DataFrame = pl.from_dicts(wall_time_results)\n",
    "memory_data: pl.DataFrame = pl.from_dicts(memory_results)\n",
    "\n",
    "combined_results: pl.DataFrame = wall_time_data.join(\n",
    "    other=memory_data, on=\"sample_size\", how=\"inner\"\n",
    ").with_columns(\n",
    "    (pl.col(\"time_roc_auc\") / pl.col(\"time_two_pointers\")).alias(\n",
    "        \"speedup_two_pointers_vs_roc_auc\"\n",
    "    ),\n",
    "    (pl.col(\"peak_mem_roc_auc_mb\") / pl.col(\"peak_mem_two_pointers_mb\")).alias(\n",
    "        \"memory_two_pointers_vs_roc_auc\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "combined_results.with_columns(cs.float().round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-for-machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
