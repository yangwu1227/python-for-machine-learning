{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Brunner, E. and Munzel, U. “The nonparametric Benhrens-Fisher problem: Asymptotic theory and a small-sample approximation”. Biometrical Journal. Vol. 42(2000): 17-25.\n",
    "\n",
    "Neubert, K. and Brunner, E. “A studentized permutation test for the non-parametric Behrens-Fisher problem”. Computational Statistics and Data Analysis. Vol. 51(2007): 5192-5204."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behrens - Fisher Problem\n",
    "\n",
    "The Behrens–Fisher problem, named after Walter-Ulrich Behrens and Ronald Fisher, involves the challenge of estimating confidence intervals and testing hypotheses for the difference in means between two normally distributed populations when their variances are not assumed to be equal, using independent samples from each population.\n",
    "\n",
    "A generalized approach to the Behrens-Fisher problem extends to a nonparametric model, where the underlying distribution functions are not assumed to be continuous, allowing for data with arbitrary ties. This approach considers a rank-based test in which the asymptotic variance is consistently estimated using both the overall ranks of all observations and the ranks within each individual sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonparametric Model & Hypothesis\n",
    "\n",
    "Let $N = n_1 + n_2$ be the total number of independent random variables:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "X_{ik} &\\sim F_i, \\quad k = 1, \\ldots, n_i \\quad \\& \\quad i = 1, 2, \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $F_i$ is the cumulative distribution function of the $i$-th treatment group since the $i \\in \\{1, 2\\}$ index denotes the treatment groups. Typically, there are two groups--- a control group and a treatment group.\n",
    "\n",
    "### Null Hypothesis\n",
    "\n",
    "The null hypothesis of no treatment effect can be formulated to include the Behren-Fisher problem as a special case:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p = P(X_{11} < X_{21}) + \\frac{1}{2}P(X_{11} = X_{21})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Here, $X_{11}$ and $X_{21}$ are random variables from two groups.\n",
    "\n",
    "#### Case $p < \\frac{1}{2}$\n",
    "\n",
    "- **Formula Breakdown:**\n",
    "\n",
    "  $$\n",
    "  p = \\textcolor{red}{P(X_{11} < X_{21})} + \\frac{1}{2}P(X_{11} = X_{21})\n",
    "  $$\n",
    "\n",
    "- For $p < \\frac{1}{2}$, this implies:\n",
    "\n",
    "  - $\\textcolor{red}{P(X_{11} < X_{21})}$ must be small.\n",
    "\n",
    "  - Even when adding $\\frac{1}{2}P(X_{11} = X_{21})$, the total value remains less than $\\frac{1}{2}$.\n",
    "\n",
    "- **Interpretation:**\n",
    "\n",
    "  - A small $P(X_{11} < X_{21})$ suggests that it is less likely for $X_{11}$ to be less than $X_{21}$.\n",
    "\n",
    "  - This means $X_{11}$ is more likely to be **greater** than $X_{21}$, indicating that values from group 1 (typically the control group) tend to be larger.\n",
    "\n",
    "#### Case $p > \\frac{1}{2}$\n",
    "\n",
    "- **Formula Breakdown:**\n",
    "\n",
    "  $$\n",
    "  p = \\textcolor{red}{P(X_{11} < X_{21})} + \\frac{1}{2}P(X_{11} = X_{21})\n",
    "  $$\n",
    "\n",
    "- For $p > \\frac{1}{2}$, this implies:\n",
    "\n",
    "  - $\\textcolor{red}{P(X_{11} < X_{21})}$ must be relatively large.\n",
    "\n",
    "  - If we add $\\frac{1}{2}P(X_{11} = X_{21})$, the total exceeds $\\frac{1}{2}$.\n",
    "\n",
    "- **Interpretation:**\n",
    "\n",
    "  - A large $P(X_{11} < X_{21})$ suggests that it is more likely for $X_{11}$ to be less than $X_{21}$.\n",
    "\n",
    "  - This means $X_{11}$ is more likely to be **smaller** than $X_{21}$, indicating that values from group 1 tend to be smaller.\n",
    "\n",
    "\n",
    "#### Case $p = \\frac{1}{2}$\n",
    "\n",
    "- **Formula Breakdown:**\n",
    "\n",
    "  $$\n",
    "  p = \\textcolor{red}{P(X_{11} < X_{21})} + \\frac{1}{2}\\textcolor{orange}{P(X_{11} = X_{21})}\n",
    "  $$\n",
    "\n",
    "- **Interpretation:**\n",
    "\n",
    "  - This indicates that $X_{11}$ and $X_{21}$ are equally likely to be less than, greater than, or equal to each other.\n",
    "\n",
    "In the context of normal distributions $F_1$ and $F_2$ with means $\\mu_1, \\mu_2$ and variances $\\sigma_1^2, \\sigma_2^2$, $p = \\frac{1}{2}$ implies $\\mu_1 = \\mu_2$, regardless of whether $\\sigma_1^2$ and $\\sigma_2^2$ are different. This matches the parametric Behrens-Fisher problem, where the focus is on comparing means even if variances differ. Thus, the nonparametric hypothesis $H_0^p: p = \\frac{1}{2}$ generalizes the Behrens-Fisher problem, encompassing it as a special case when the distributions are normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation of the Relative Treatment Effect\n",
    "\n",
    "The relative treatment effect $p$ is a measure used to compare two distributions, typically representing the effect of a treatment versus a control group. It quantifies the probability that a randomly selected observation from one group (say, treatment) is greater than a randomly selected observation from the other group (control).\n",
    "\n",
    "**Normalized Version of the Distribution Function**\n",
    "\n",
    "- To express $p$ in terms of the distribution functions, the normalized version of the distribution function is used:\n",
    "  $$\n",
    "  F_i(x) = \\frac{1}{2}\\left[F_i^{-}(x) + F_i^{+}(x)\\right] \\quad \\text{for } i = 1, 2\n",
    "  $$\n",
    "  Here:\n",
    "  - $F_i(x)$ is the distribution function for group $i$.\n",
    "  - $F_i^{-}(x) = P(X_{i1} < x)$ is the left-continuous version of the distribution function. It calculates the probability of observing a value less than $x$.\n",
    "  - $F_i^{+}(x) = P(X_{i1} \\leq x)$ is the right-continuous version, calculating the probability of observing a value less than or equal to $x$.\n",
    "\n",
    "  The average of these two versions, $\\frac{1}{2}(F_i^{-}(x) + F_i^{+}(x))$, provides a normalized version of the distribution function, making it convenient for theoretical derivations and avoiding ambiguity at discontinuity points.\n",
    "\n",
    "**Expression for the Relative Treatment Effect ($p$)**\n",
    "\n",
    "- The relative treatment effect $p$ can then be written as:\n",
    "  $$\n",
    "  p = \\int F_1 \\, dF_2\n",
    "  $$\n",
    "  This integral represents the average value of $F_1$ when weighted by the distribution $F_2$. Essentially, it measures the probability that a value from the distribution represented by $F_1$ is greater than or equal to a value from $F_2$. This expression allows for an easy computation of $p$ under different distribution assumptions.\n",
    "\n",
    "**Hypothesis of No Treatment Effect ($H_0^p$)**\n",
    "\n",
    "- The null hypothesis of no treatment effect is expressed as:\n",
    "  $$\n",
    "  H_0^p: p = \\int F_1 \\, dF_2 = \\frac{1}{2}\n",
    "  $$\n",
    "  This states that if there is no effect of the treatment, the probability of a value from the treatment distribution being greater than or equal to a value from the control distribution is 0.5. This would indicate that the treatment and control groups are equally likely to yield higher or lower values, implying no difference between them.\n",
    "\n",
    "**Relation to the Hypothesis $H_0^F$**\n",
    "\n",
    "- The hypothesis $H_0^F: F_1 = F_2 = F$ implies that the distribution functions of both groups (treatment and control) are the same.\n",
    "- If $F_1$ and $F_2$ are equal, then:\n",
    "  $$\n",
    "  p = \\int F \\, dF = \\frac{1}{2}\n",
    "  $$\n",
    "  This follows from the property of integration by parts. Intuitively, if the two groups have identical distributions, the chance that one group has higher values than the other is exactly 50%, confirming that there is no treatment effect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Statistic\n",
    "\n",
    "### Empirical Distribution Function\n",
    "\n",
    "   - The empirical distribution function is defined as:\n",
    "   $$\n",
    "   \\hat{F}_i(x) = \\frac{1}{2}\\left[\\hat{F}_i^{-}(x) + \\hat{F}_i^{+}(x)\\right]\n",
    "   $$\n",
    "   - **Explanation**:\n",
    "\n",
    "     - $ \\hat{F}_i(x) $: Empirical distribution function for group $ i $.\n",
    "\n",
    "     - $ \\hat{F}_i^{-}(x) $: Left-continuous version of the empirical distribution function, which counts the probability of observing values strictly less than $ x $.\n",
    "\n",
    "     - $ \\hat{F}_i^{+}(x) $: Right-continuous version of the empirical distribution function, which counts the probability of observing values less than or equal to $ x $.\n",
    "     \n",
    "     - The average of these two versions gives a normalized and continuous empirical distribution function.\n",
    "\n",
    "### Combined Distribution Function\n",
    "\n",
    "   - The combined distribution function is given by:\n",
    "   $$\n",
    "   H(x) = \\sum_{i=1}^2 \\frac{n_i}{N} F_i(x)\n",
    "   $$\n",
    "   - The empirical version:\n",
    "   $$\n",
    "   \\hat{H}(x) = \\sum_{i=1}^2 \\frac{n_i}{N} \\hat{F}_i(x)\n",
    "   $$\n",
    "   - **Explanation**:\n",
    "\n",
    "     - $ H(x) $ and $ \\hat{H}(x) $: Combined (true and empirical) distribution functions, weighted by the sample sizes.\n",
    "\n",
    "     - $ n_i $: The size of group $ i $.\n",
    "\n",
    "     - $ N = n_1 + n_2 $: Total number of observations from both groups.\n",
    "\n",
    "     - $ F_i(x) $ and $ \\hat{F}_i(x) $: Distribution function and empirical distribution function for group $ i $.\n",
    "\n",
    "### Rank of an Observation\n",
    "\n",
    "   - The rank of an observation $ X_{ij} $ among all $ N $ observations is:\n",
    "   $$\n",
    "   R_{ik} = N \\cdot \\hat{H}\\left(X_{ik}\\right) + \\frac{1}{2}\n",
    "   $$\n",
    "   - **Explanation**:\n",
    "\n",
    "     - $ R_{ik} $: Rank of the $ k $-th observation in group $ i $ within the entire dataset.\n",
    "\n",
    "     - $ \\hat{H}\\left(X_{ik}\\right) $: Value of the empirical combined distribution function evaluated at $ X_{ik} $.\n",
    "\n",
    "     - The term $ \\frac{1}{2} $ accounts for mid-ranking in the case of ties.\n",
    "\n",
    "### Mean Rank in a Group\n",
    "\n",
    "   - The mean rank in group $ i $ is:\n",
    "   $$\n",
    "   \\bar{R}_i = \\frac{1}{n_i} \\sum_{j=1}^{n_i} R_{ij}\n",
    "   $$\n",
    "   - **Explanation**:\n",
    "\n",
    "     - $ \\bar{R}_i $: Mean of the ranks for observations in group $ i $.\n",
    "\n",
    "     - $ R_{ij} $: Rank of each observation in group $ i $.\n",
    "\n",
    "     - The mean rank is calculated by averaging the ranks within group $ i $.\n",
    "\n",
    "### Estimator for $ p $\n",
    "\n",
    "   - The estimator for the relative treatment effect $ p $ is:\n",
    "   $$\n",
    "   \\hat{p}=\\int \\hat{F}_1 \\mathrm{~d} \\hat{F}_2=\\frac{1}{n_1}\\left(\\bar{R}_2-\\frac{n_2+1}{2}\\right)\n",
    "   $$\n",
    "   - **Explanation**:\n",
    "\n",
    "     - $ \\hat{p} $: Estimator for the relative treatment effect.\n",
    "\n",
    "     - $ \\bar{R}_2 $: Mean rank of group 2 (typically the treatment group).\n",
    "\n",
    "     - $ n_2 $: Size of group 2.\n",
    "     \n",
    "     - $ \\frac{n_2 + 1}{2} $: Adjustment term for scaling the mean rank.\n",
    "\n",
    "### Unbiasedness of $ \\hat{p} $\n",
    "\n",
    "   - The unbiasedness follows from:\n",
    "   $$\n",
    "   E\\left[c\\left(X_{21} - X_{11}\\right)\\right] = \\int F_1 \\, dF_2\n",
    "   $$\n",
    "   - **Explanation**:\n",
    "     - $ E\\left[c\\left(X_{21} - X_{11}\\right)\\right] $: Expectation of a count function comparing observations from the two groups.\n",
    "     - $ c(u) = 0, \\frac{1}{2}, 1 $ depending on whether $ u <, =, > 0 $. This is the normalized count function defined as:\n",
    "\n",
    "       $$\n",
    "        c(u) = \n",
    "        \\begin{cases} \n",
    "        0 & \\text{if } u < 0 \\\\\n",
    "        \\frac{1}{2} & \\text{if } u = 0 \\\\\n",
    "        1 & \\text{if } u > 0\n",
    "        \\end{cases}\n",
    "      $$\n",
    "\n",
    "        Where:\n",
    "        $$\n",
    "        u = X_{21} - X_{11}\n",
    "        $$\n",
    "        - $X_{21}$: Observation from the treatment group.\n",
    "        - $X_{11}$: Observation from the control group.\n",
    "\n",
    "        This function assigns:\n",
    "\n",
    "        - $0$ if the treatment group observation is less than the control group’s.\n",
    "        - $\\frac{1}{2}$ if the observations are equal (a tie).\n",
    "        - $1$ if the treatment group observation is greater.\n",
    "\n",
    "        This function, when averaged over all pairs of observations from the two groups, gives an estimate of the probability that a treatment group observation is greater than, equal to, or less than a control group observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymptotic Normality\n",
    "\n",
    "The asymptotic normality of the statistic is:\n",
    "\n",
    "$$\n",
    "\\frac{\\sqrt{N}\\left(\\hat{p} - \\frac{1}{2}\\right)}{\\sigma_N} \\xrightarrow{d} \\mathcal{N}(0, 1)\n",
    "$$\n",
    "\n",
    "where:\n",
    "$$\n",
    "\\sigma_N^2 = N\\left[\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}\\right]\n",
    "$$\n",
    "\n",
    "and:\n",
    "\n",
    "- $\\sigma_1^2 = \\operatorname{Var}\\left(F_2(X_{11})\\right)$: Variance of the cumulative distribution function $F_2$ evaluated at observations from the control group.\n",
    "   \n",
    "- $\\sigma_2^2 = \\operatorname{Var}\\left(F_1(X_{21})\\right)$: Variance of the cumulative distribution function $F_1$ evaluated at observations from the treatment group.\n",
    "\n",
    "The statistic $\\frac{\\sqrt{N}\\left(\\hat{p} - \\frac{1}{2}\\right)}{\\sigma_N}$ follows an asymptotic standard normal distribution $\\mathcal{N}(0, 1)$ as $N \\to \\infty$, under the null hypothesis $H_0^p: p = \\frac{1}{2}$.\n",
    "\n",
    "### Variance Estimation\n",
    "\n",
    "Note that, even under $H_0^p$, the variances $\\sigma_1^2$ and $\\sigma_2^2$ are unknown and must be estimated from the data. To do this, let \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Y_{1k} = F_2\\left(X_{1k}\\right), k=1, \\ldots, n_1\n",
    "\\end{align*}\n",
    "$$ \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Y_{2k} = F_1\\left(X_{2k}\\right), k=1, \\ldots, n_2\n",
    "\\end{align*}\n",
    "$$ \n",
    "\n",
    "The random variables $Y_{1k}$ and $Y_{2k}$ are independent by assumption. Given these, the quantities \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\tilde{\\sigma}_i^2 = \\frac{1}{n_i-1} \\sum_{k=1}^{n_i}\\left(Y_{ik} - \\bar{Y}_{i\\cdot}\\right)^2\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "are unbiased and consistent for $\\sigma_i^2, i=1,2$. \n",
    "\n",
    "Since the random variables $Y_{ik}$ are unobservable, they must be replaced with observable variables \"close enough\" to the $Y_{ik}$. We replace the distribution functions $F_i(x)$ with their empirical counterparts $\\hat{F}_i(x), i=1,2$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "n_1 \\hat{F}_1\\left(X_{2k}\\right) &= N \\hat{H}\\left(X_{2k}\\right) - n_2 \\hat{F}_2\\left(X_{2k}\\right) = R_{2k} - R_{2k}^{(2)} \\\\\n",
    "n_2 \\hat{F}_2\\left(X_{1k}\\right) &= N \\hat{H}\\left(X_{1k}\\right) - n_1 \\hat{F}_1\\left(X_{1k}\\right) = R_{1k} - R_{1k}^{(1)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "* $R_{ik} = N \\hat{H}\\left(X_{ik}\\right) + \\frac{1}{2}$ denotes the rank of $X_{ik}$ among all $N$ observations\n",
    "* $R_{ik}^{(i)} = n_i \\hat{F}_i\\left(X_{ik}\\right) + \\frac{1}{2}$ denotes the (within) rank of $X_{ik}$ among the $n_i$ observations within the $i$-th group $X_{i1}, \\ldots, X_{in_i}, i=1,2$. \n",
    "\n",
    "In the case of ties, the mid-ranks come out automatically as already noted for the (overall) ranks $R_{ik} = N \\hat{H}\\left(X_{ik}\\right) + \\frac{1}{2}$. Then, the variances $\\sigma_i^2$ are estimated by:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\sigma}_i^2 = \\frac{S_i^2}{\\left(N - n_i\\right)^2}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $S_i^2 = \\frac{1}{n_i-1} \\sum_{k=1}^{n_i}\\left(R_{ik} - R_{ik}^{(i)} - \\bar{R}_i + \\frac{n_i + 1}{2}\\right)^2$ is the empirical variance of $R_{ik} - R_{ik}^{(i)}, k=1, \\ldots, n_i, i=1,2$.\n",
    "\n",
    "The estimator $\\hat{\\sigma}_i^2$ is consistent for $\\sigma_i^2$, as $E\\left(\\frac{\\hat{\\sigma}_i^2}{\\sigma_i^2} - 1\\right)^2 \\rightarrow 0, i=1,2$. Thus, under $H_0^p$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\sigma}_N^2 = N \\cdot\\left[\\frac{\\hat{\\sigma}_1^2}{n_1} + \\frac{\\hat{\\sigma}_2^2}{n_2}\\right]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "is consistent for $\\sigma_N^2$, and it follows that the statistic:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "W_N^{BF} = \\frac{\\sqrt{N}\\left(\\hat{p} - \\frac{1}{2}\\right)}{\\hat{\\sigma}_N} = \\frac{1}{\\sqrt{N}} \\cdot \\frac{\\bar{R}_2 - \\bar{R}_1}{\\hat{\\sigma}_N}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "has, asymptotically, a standard normal distribution under the hypothesis $H_0^p: p = \\frac{1}{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Sample Approximation (Central $t$-Distribution)\n",
    "\n",
    "Based on simulation studies, the distribution of $\\hat{\\sigma}_N^2 = N \\cdot\\left[\\frac{\\hat{\\sigma}_1^2}{n_1} + \\frac{\\hat{\\sigma}_2^2}{n_2}\\right]$ becomes degenerate quickly, at the rate of $1 / N$, since $\\hat{\\sigma}_N^2$ is consistent for $\\sigma_N^2$. \n",
    "\n",
    "As a result, the small sample distribution of $W_N^{BF}$ may be approximated by a distribution that converges to the standard normal distribution as the sample size increases. A simulation study showed that the quality of this approximation depends mainly on the **ratio of the variances**, the **individual sample sizes** $n_i$, and the **total sample size** $N$.\n",
    "\n",
    "To address small sample sizes, an approximation using a $t$-distribution is employed, where the degrees of freedom are based on the parametric Satterthwaite-Satterthwaite-Welch (SSW) approximation. Specifically, for small samples, the null distribution of $W_N^{BF}$ is approximated by a central $t$-distribution with:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{f} &= \\frac{\\left(\\sum_{i=1}^2 \\frac{\\hat{\\sigma}_i^2}{n_i}\\right)^2}{\\sum_{i=1}^2 \\frac{\\left(\\hat{\\sigma}_i^2 / n_i\\right)^2}{\\left(n_i-1\\right)}} \\\\\n",
    "&= \\frac{\\left(\\sum_{i=1}^2 \\frac{S_i^2}{\\left(N-n_i\\right)}\\right)^2}{\\sum_{i=1}^2 \\frac{\\left[S_i^2 /\\left(N-n_i\\right)\\right]^2}{\\left(n_i-1\\right)}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "degrees of freedom, where $S_i^2$ is defined as, again:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "S_i^2 = \\frac{1}{n_i-1} \\sum_{k=1}^{n_i}\\left(R_{ik} - R_{ik}^{(i)} - \\bar{R}_i + \\frac{n_i + 1}{2}\\right)^2\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "As $\\hat{f} \\rightarrow \\infty$, the $t_{\\hat{f}}$-distribution converges to the standard normal distribution, making the approximation asymptotically accurate.\n",
    "\n",
    "### Rough Rule of Thumb \n",
    "\n",
    "> The test based on the statistic $W_{N}^{BF}$ however, was more or less liberal for medium or small sample sizes (smaller than about 50) and was quite accurate for larger sample sizes.\n",
    "\n",
    "Therefore, for $n_i \\leq 50$, the $t$-distribution approximation is recommended, while for larger sample sizes, the standard normal distribution approximation is sufficient.\n",
    "\n",
    "For $n_i < 10$, the permutation test is recommended, as the $t$-distribution approximation cannot be expected to be accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clinical Trial Example\n",
    "\n",
    "In this example, the statistic $W_N^{BF}$ and its $t$-distribution approximation with $\\hat{f}$ degrees of freedom are applied to a clinical trial from [Lumley (1996)](https://pubmed.ncbi.nlm.nih.gov/9032714/). The trial observed ordinal pain scores (1–5) for 25 female patients post-laparoscopic surgery. Two treatments (active $Y$ and control $N$) were randomly assigned: 14 patients received $Y$ and 11 received $N$. The table below shows the pain scores on the third day after surgery.\n",
    "\n",
    "<center>\n",
    "\n",
    "| Treatment | Pain Scores          |\n",
    "|-----------|----------------------|\n",
    "| $Y$       | 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 1, 1 |\n",
    "| $N$       | 3, 3, 4, 3, 1, 2, 3, 1, 1, 5, 4          |\n",
    "\n",
    "</center>\n",
    "\n",
    "The physician aimed to determine if the pain scores for $Y$ were generally lower than for $N$. The relative treatment effect is defined as $p = \\int F_1 \\, dF_2$, where $F_1$ and $F_2$ are distributions for $Y$ and $N$, respectively. \n",
    "\n",
    "Testing $H_0^p: p = \\frac{1}{2}$ against $H_1^p: p > \\frac{1}{2} = \\textcolor{red}{P(X_{11} < X_{21})} + \\frac{1}{2}P(X_{11} = X_{21})$ is appropriate. The benefit of $Y$ can be estimated by $\\hat{p} = \\frac{\\bar{R}_2 - \\frac{(n_2+1)}{2}}{n_1}$, where $\\bar{R}_2$ is the mean of mid-ranks of the observed pain scores under the control treatment. A non-parametric test is preferred as pain scores are ordered categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np \n",
    "from scipy.stats import brunnermunzel, rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14,), (11,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment = np.array([1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 1, 1])\n",
    "control = np.array([3, 3, 4, 3, 1, 2, 3, 1, 1, 5, 4])\n",
    "\n",
    "treatment.shape, control.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BrunnerMunzelResult(statistic=np.float64(-3.1374674823029505), pvalue=np.float64(0.002893104333075734))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The alternative hypothesis is that the control group is greater than the treatment group\n",
    "brunnermunzel(x=control, y=treatment, alternative='greater', distribution='t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute $\\hat{p} = \\frac{\\bar{R}_2 - \\frac{(n_2+1)}{2}}{n_1}$ using a function from [statsmodels](https://www.statsmodels.org/stable/generated/statsmodels.stats.nonparametric.rankdata_2samp.html#statsmodels.stats.nonparametric.rankdata_2samp):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankdata_2samp(x1: np.ndarray, x2: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute midranks for two samples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x1, x2 : array_like\n",
    "        Original data for two samples that will be converted to midranks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rank1 : ndarray\n",
    "        Midranks of the first sample in the pooled sample.\n",
    "    rank2 : ndarray\n",
    "        Midranks of the second sample in the pooled sample.\n",
    "    ranki1 : ndarray\n",
    "        Internal midranks of the first sample.\n",
    "    ranki2 : ndarray\n",
    "        Internal midranks of the second sample.\n",
    "    \"\"\"\n",
    "    x1 = np.asarray(x1)\n",
    "    x2 = np.asarray(x2)\n",
    "\n",
    "    nobs1 = len(x1)\n",
    "    nobs2 = len(x2)\n",
    "    if nobs1 == 0 or nobs2 == 0:\n",
    "        raise ValueError(\"One sample has zero length\")\n",
    "\n",
    "    x_combined = np.concatenate((x1, x2))\n",
    "    rank = rankdata(x_combined, method=\"average\")  # Compute midranks for the pooled data\n",
    "    rank1 = rank[:nobs1]\n",
    "    rank2 = rank[nobs1:]\n",
    "\n",
    "    ranki1 = rankdata(x1)  # Internal ranks for x1 (i.e., the ranks of each element of x1 within x1)\n",
    "    ranki2 = rankdata(x2)  # Internal ranks for x2 (i.e., the ranks of each element of x2 within x2)\n",
    "\n",
    "    return rank1, rank2, ranki1, ranki2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(17.045454545454547), np.float64(9.821428571428571))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_control, rank_treatment, _, _ = rankdata_2samp(control, treatment)\n",
    "\n",
    "n_control, n_treatment = len(control), len(treatment)\n",
    "\n",
    "mean_rank_control = np.mean(rank_control)\n",
    "mean_rank_treatment = np.mean(rank_treatment)\n",
    "\n",
    "mean_rank_control, mean_rank_treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative treatment effect estimate: 0.7890\n"
     ]
    }
   ],
   "source": [
    "relative_treatment_effect_estimate = (mean_rank_control - (n_control + 1) / 2) / n_treatment\n",
    "\n",
    "print(f\"Relative treatment effect estimate: {relative_treatment_effect_estimate:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_for_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
