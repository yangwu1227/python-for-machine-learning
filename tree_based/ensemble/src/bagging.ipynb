{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging in Scikit-Learn\n",
    "\n",
    "## Table of Content \n",
    "\n",
    "- [Imports](#imports)\n",
    "- [Classification](#classification)\n",
    "  - [Data](#data)\n",
    "  - [Convert Text To Vectors](#convert-text-to-vectors)\n",
    "  - [Bagging](#bagging)\n",
    "  - [Accuracy Compared to A Single Decision Tree](#accuracy-compared-to-a-single-decision-tree)\n",
    "- [Regression](#regression)\n",
    "  - [Data](#data)\n",
    "  - [Pipeline](#pipeline)\n",
    "  - [Bagging](#bagging)\n",
    "  - [Accuracy Compared to A Single Decision Tree](#accuracy-compared-to-a-single-decision-tree)\n",
    "  - [Bagged Model Performance On Training Data](#bagged-model-performance-on-training-data)\n",
    "  - [Bagged Model Performance On Test Data](#bagged-model-performance-on-test-data)\n",
    "  - [Single Decision Tree Performance On Training Data](#single-decision-tree-performance-on-training-data)\n",
    "  - [Single Decision Tree Performance On Test Data](#single-decision-tree-performance-on-test-data)\n",
    "  - [Performance Table](#performance-table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive shell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Data wrangling and standard library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.datasets import fetch_20newsgroups, fetch_20newsgroups_vectorized\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "# Utilities\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a bunch object\n",
    "newsgroups = fetch_20newsgroups(subset=\"train\", random_state=1227)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attributes of bunch\n",
    "newsgroups.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n",
       "       'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
       "       'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles',\n",
       "       'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt',\n",
       "       'sci.electronics', 'sci.med', 'sci.space',\n",
       "       'soc.religion.christian', 'talk.politics.guns',\n",
       "       'talk.politics.mideast', 'talk.politics.misc',\n",
       "       'talk.religion.misc'], dtype='<U24')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique target values\n",
    "np.unique(newsgroups[\"target\"])\n",
    "np.unique(newsgroups[\"target_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "The 20 newsgroups text dataset\n",
       "------------------------------\n",
       "\n",
       "The 20 newsgroups dataset comprises around 18000 newsgroups posts on\n",
       "20 topics split in two subsets: one for training (or development)\n",
       "and the other one for testing (or for performance evaluation). The split\n",
       "between the train and test set is based upon a messages posted before\n",
       "and after a specific date.\n",
       "\n",
       "This module contains two loaders. The first one,\n",
       ":func:`sklearn.datasets.fetch_20newsgroups`,\n",
       "returns a list of the raw texts that can be fed to text feature\n",
       "extractors such as :class:`sklearn.feature_extraction.text.CountVectorizer`\n",
       "with custom parameters so as to extract feature vectors.\n",
       "The second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\n",
       "returns ready-to-use features, i.e., it is not necessary to use a feature\n",
       "extractor.\n",
       "\n",
       "**Data Set Characteristics:**\n",
       "\n",
       "    =================   ==========\n",
       "    Classes                     20\n",
       "    Samples total            18846\n",
       "    Dimensionality               1\n",
       "    Features                  text\n",
       "    =================   ==========\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Description of the data\n",
    "display(Markdown(newsgroups[\"DESCR\"][25:1086]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Text To Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a collection of raw documents to a matrix of TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train, y_train = vectorizer.fit_transform(newsgroups.data), newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "When random subsets of the dataset are drawn as random subsets of the samples (*without replacement*), then this algorithm is known as **Pasting**. If samples are drawn *with replacement*, then the method is known as **Bagging**. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as **Random Subspaces**. Finally, when base estimators are built on subsets of both samples and features, then the method is known as **Random Patches**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(),\n",
    "    # Number of base estimators in the ensemble\n",
    "    n_estimators=300,\n",
    "    # Bootstrap samples with replacement\n",
    "    bootstrap=True,\n",
    "    # Use out-of-bag samples to estimate the generalization error\n",
    "    oob_score=True,\n",
    "    random_state=1227,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `BaggingClassifier` meta-estimator, parameters `max_samples` and `max_features` control the size of the subsets (in terms of samples and features), while `bootstrap` and `bootstrap_features` control whether samples and features are drawn with or without replacement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed: 25.2min remaining: 75.5min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed: 25.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=300,\n",
       "                  n_jobs=-1, oob_score=True, random_state=1227, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/bagging/bagging_classifier_newsgroup.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bag_clf, \"../models/bagging/bagging_classifier_newsgroup.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-Of-Bag\n",
    "\n",
    "The out-of-bag score for the bagged model is as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7534028637086795"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision function computed with out-of-bag estimate on the training set is stored in `oob_decision_function_`. If `n_estimators` is small, it might be possible that a data point was never left out during the bootstrap. In this case, oob_decision_function_ might contain NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for data points that were never left out\n",
    "np.isnan(bag_clf.oob_decision_function_).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the base estimator `DecisionTreeClassifier` has the `predict_proba` method, which predicts class probabilities of the input samples `X`. The decision function also returns the class probabilities for each training instance. For the first training sample, the bagged classifier predicts with probability 0.205607476635514:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02803738, 0.04672897, 0.09345794, 0.02803738, 0.04672897,\n",
       "        0.        , 0.00934579, 0.20560748, 0.10280374, 0.01869159,\n",
       "        0.04672897, 0.04672897, 0.12149533, 0.05607477, 0.04672897,\n",
       "        0.00934579, 0.02803738, 0.00934579, 0.02803738, 0.02803738]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max is 0.205607476635514\n"
     ]
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_[:1, :]\n",
    "print(\"The max is\", bag_clf.oob_decision_function_[:1, :].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second training sample, the bagged model predicts with probability 0.388889:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.38888889, 0.11111111, 0.05555556, 0.02777778,\n",
       "        0.        , 0.02777778, 0.02777778, 0.        , 0.        ,\n",
       "        0.        , 0.02777778, 0.16666667, 0.        , 0.05555556,\n",
       "        0.02777778, 0.        , 0.        , 0.        , 0.08333333]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max is 0.3888888888888889\n"
     ]
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_[1:2, :]\n",
    "print(\"The max is\", bag_clf.oob_decision_function_[1:2, :].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so on....\n",
    "\n",
    "### Accuracy Compared to A Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test, y_test = fetch_20newsgroups_vectorized(subset=\"test\", return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7532, 130107)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(7532,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bagged model achieved an accuracy score of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    4.9s remaining:   14.7s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    6.2s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred_bagged = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66064790228359\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_bagged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this is still subpar. This is in contrast to a single decision tree, which has an accuracy of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=1227)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.516064790228359\n"
     ]
    }
   ],
   "source": [
    "# Single tree\n",
    "tree_clf = DecisionTreeClassifier(random_state=1227)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the bagged model has improved the accuracy by $(\\frac{0.66064790228359}{0.516064790228359} - 1) \\times 100 \\approx 28.0165 \\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "X_train, y_train = (\n",
    "    joblib.load(\"../../../california_housing_price_project/dataset/training_X.pkl\"),\n",
    "    joblib.load(\"../../../california_housing_price_project/dataset/training_y.pkl\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8088</th>\n",
       "      <td>-118.21</td>\n",
       "      <td>33.82</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1719.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>2.8438</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15259</th>\n",
       "      <td>-117.27</td>\n",
       "      <td>33.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>3.9826</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>-122.08</td>\n",
       "      <td>37.68</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>2.4196</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12828</th>\n",
       "      <td>-121.45</td>\n",
       "      <td>38.70</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2159.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>3.9853</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18294</th>\n",
       "      <td>-122.10</td>\n",
       "      <td>37.39</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2471.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>7.6229</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8285</th>\n",
       "      <td>-118.14</td>\n",
       "      <td>33.77</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2812.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>3.8750</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20569</th>\n",
       "      <td>-121.76</td>\n",
       "      <td>38.66</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>984.0</td>\n",
       "      <td>2866.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>4.1997</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12632</th>\n",
       "      <td>-121.48</td>\n",
       "      <td>38.49</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3165.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>2447.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>1.5908</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5135</th>\n",
       "      <td>-118.26</td>\n",
       "      <td>33.97</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>-118.45</td>\n",
       "      <td>37.25</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.0817</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16511 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "8088     -118.21     33.82                34.0       1719.0           398.0   \n",
       "15259    -117.27     33.03                25.0       1787.0           311.0   \n",
       "710      -122.08     37.68                26.0       1167.0           370.0   \n",
       "12828    -121.45     38.70                24.0       2159.0           369.0   \n",
       "18294    -122.10     37.39                35.0       2471.0           349.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "8285     -118.14     33.77                51.0       2812.0           621.0   \n",
       "20569    -121.76     38.66                17.0       5320.0           984.0   \n",
       "12632    -121.48     38.49                26.0       3165.0           806.0   \n",
       "5135     -118.26     33.97                46.0       1521.0           352.0   \n",
       "2786     -118.45     37.25                20.0       1468.0           283.0   \n",
       "\n",
       "       population  households  median_income ocean_proximity  \n",
       "8088       1444.0       372.0         2.8438      NEAR OCEAN  \n",
       "15259      1108.0       311.0         3.9826      NEAR OCEAN  \n",
       "710         253.0       137.0         2.4196        NEAR BAY  \n",
       "12828      1141.0       355.0         3.9853          INLAND  \n",
       "18294       881.0       342.0         7.6229        NEAR BAY  \n",
       "...           ...         ...            ...             ...  \n",
       "8285       1171.0       566.0         3.8750      NEAR OCEAN  \n",
       "20569      2866.0       928.0         4.1997          INLAND  \n",
       "12632      2447.0       752.0         1.5908          INLAND  \n",
       "5135       1100.0       334.0         1.5500       <1H OCEAN  \n",
       "2786        721.0       270.0         3.0817          INLAND  \n",
       "\n",
       "[16511 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8088     139300.0\n",
       "15259    215800.0\n",
       "710      275000.0\n",
       "12828     90400.0\n",
       "18294    500001.0\n",
       "           ...   \n",
       "8285     342900.0\n",
       "20569    133400.0\n",
       "12632     78600.0\n",
       "5135     100600.0\n",
       "2786     118800.0\n",
       "Name: median_house_value, Length: 16511, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "col_names = [\"total_rooms\", \"total_bedrooms\", \"population\", \"households\"]\n",
    "# List comprehension and unpack to get column indexes, which are essentially the integer locations of these columns\n",
    "rooms_id, bedrooms_id, population_id, households_id = [\n",
    "    X_train.columns.get_loc(col) for col in col_names\n",
    "]\n",
    "\n",
    "\n",
    "# Custom transformer\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    # Constructor\n",
    "    def __init__(self, add_bedrooms_per_room=True):\n",
    "        # Hyperparameter for controlling feature engineering\n",
    "        # If true, then add the new attribute 'bedrooms_per_room'\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Create new attributes\n",
    "        rooms_per_household = X[:, rooms_id] / X[:, households_id]\n",
    "        population_per_household = X[:, population_id] / X[:, households_id]\n",
    "        # If the hyperparameter self.add_bedrooms_per_room = True\n",
    "        if self.add_bedrooms_per_room:\n",
    "            # Create this attribute\n",
    "            bedrooms_per_room = X[:, bedrooms_id] / X[:, rooms_id]\n",
    "            # Include these additional attributes in the transformed feature matrix\n",
    "            return np.c_[\n",
    "                X, rooms_per_household, population_per_household, bedrooms_per_room\n",
    "            ]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for preprocessing the numerical attributes\n",
    "numerical_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"attr_adder\", CombinedAttributesAdder(add_bedrooms_per_room=True)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['longitude',\n",
       "  'latitude',\n",
       "  'housing_median_age',\n",
       "  'total_rooms',\n",
       "  'total_bedrooms',\n",
       "  'population',\n",
       "  'households',\n",
       "  'median_income'],\n",
       " ['ocean_proximity'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrapping a data frame object in a list() function returns a list of column names\n",
    "numerical_attributes = list(X_train.select_dtypes(include=np.number))\n",
    "categorical_attributes = list(X_train.select_dtypes(include=object))\n",
    "numerical_attributes, categorical_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical\", numerical_pipeline, numerical_attributes),\n",
    "        (\n",
    "            \"categorical\",\n",
    "            OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\"),\n",
    "            categorical_attributes,\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-118.21,   33.82,   34.  , ...,    0.  ,    0.  ,    1.  ],\n",
       "       [-117.27,   33.03,   25.  , ...,    0.  ,    0.  ,    1.  ],\n",
       "       [-122.08,   37.68,   26.  , ...,    0.  ,    1.  ,    0.  ],\n",
       "       ...,\n",
       "       [-121.48,   38.49,   26.  , ...,    0.  ,    0.  ,    0.  ],\n",
       "       [-118.26,   33.97,   46.  , ...,    0.  ,    0.  ,    0.  ],\n",
       "       [-118.45,   37.25,   20.  , ...,    0.  ,    0.  ,    0.  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(16511, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_train\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_reg = BaggingRegressor(\n",
    "    base_estimator=DecisionTreeRegressor(),\n",
    "    # Number of base estimators in the ensemble\n",
    "    n_estimators=500,\n",
    "    # Bootstrap samples with replacement\n",
    "    bootstrap=True,\n",
    "    # Use out-of-bag samples to estimate the generalization error\n",
    "    oob_score=True,\n",
    "    random_state=1227,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=500,\n",
       "                 n_jobs=-1, oob_score=True, random_state=1227)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/bagging/bagging_regressor_ca_housing.pkl']"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bag_reg, \"../models/bagging/bagging_regressor_ca_housing.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-Of-Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8146932417823896"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_reg.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(bag_reg.oob_prediction_).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([150874.34554974, 166508.99470899, 207767.69154229, ...,\n",
       "        73166.14583333,  95226.08695652, 113365.57377049])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(16511,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_reg.oob_prediction_\n",
    "bag_reg.oob_prediction_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Compared to A Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = (\n",
    "    joblib.load(\"../../../california_housing_price_project/dataset/test_X.pkl\"),\n",
    "    joblib.load(\"../../../california_housing_price_project/dataset/test_y.pkl\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged Model Performance On Training Data\n",
    "\n",
    "The bagged model has the following values for $\\hat{\\sigma}^{2}$ (mean squared error) and root mean squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_bagged = bag_reg.predict(X_train)\n",
    "# Obtain MSE and RMSE\n",
    "MSE, RMSE = (\n",
    "    mean_squared_error(y_true=y_train, y_pred=y_pred_bagged, squared=True),\n",
    "    mean_squared_error(y_true=y_train, y_pred=y_pred_bagged, squared=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSE=336456540.8859869 and RMSE=18342.751726117513'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"MSE={MSE} and RMSE={RMSE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged Model Performance On Test Data\n",
    "\n",
    "One the test set, the bagged model has the following performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pipeline to test data\n",
    "X_test = pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_bagged_test = bag_reg.predict(X_test)\n",
    "# Obtain MSE and RMSE\n",
    "MSE_test, RMSE_test = (\n",
    "    mean_squared_error(y_true=y_test, y_pred=y_pred_bagged_test, squared=True),\n",
    "    mean_squared_error(y_true=y_test, y_pred=y_pred_bagged_test, squared=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSE=2336630343.16881 and RMSE=48338.70440101607'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"MSE={MSE_test} and RMSE={RMSE_test}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Decision Tree Performance On Training Data\n",
    "\n",
    "On the other hand, the single decision tree grossly overfits. On the training data, the mean square error is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1227)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single tree\n",
    "tree_reg = DecisionTreeRegressor(random_state=1227)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "y_pred_tree = tree_reg.predict(X_train)\n",
    "# Obtain MSE and RMSE\n",
    "MSE_tree, RMSE_tree = (\n",
    "    mean_squared_error(y_true=y_train, y_pred=y_pred_tree, squared=True),\n",
    "    mean_squared_error(y_true=y_train, y_pred=y_pred_tree, squared=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSE=0.0 and RMSE=0.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"MSE={MSE_tree} and RMSE={RMSE_tree}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Decision Tree Performance On Test Data\n",
    "\n",
    "On the test set, the single decision tree performs worse than the bagged model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree_test = tree_reg.predict(X_test)\n",
    "# Obtain MSE and RMSE\n",
    "MSE_tree_test, RMSE_tree_test = (\n",
    "    mean_squared_error(y_true=y_test, y_pred=y_pred_tree_test, squared=True),\n",
    "    mean_squared_error(y_true=y_test, y_pred=y_pred_tree_test, squared=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSE=4770561447.170502 and RMSE=69069.25109750722'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"MSE={MSE_tree_test} and RMSE={RMSE_tree_test}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Performance</th>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE (Training Data)</td>\n",
       "      <td>18342.751726</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE (Test Data)</td>\n",
       "      <td>48338.704401</td>\n",
       "      <td>69069.251098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Performance  BaggingRegressor  DecisionTreeRegressor\n",
       "0  RMSE (Training Data)      18342.751726               0.000000\n",
       "1      RMSE (Test Data)      48338.704401           69069.251098"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_table = pd.DataFrame(\n",
    "    {\n",
    "        \"Performance\": [\"RMSE (Training Data)\", \"RMSE (Test Data)\"],\n",
    "        \"BaggingRegressor\": [RMSE, RMSE_test],\n",
    "        \"DecisionTreeRegressor\": [RMSE_tree, RMSE_tree_test],\n",
    "    }\n",
    ")\n",
    "perf_table"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40fc6ebffc74793621f684cf09d9f3d0a501c91440a6f462aebac8d38ed47133"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('python_for_machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
